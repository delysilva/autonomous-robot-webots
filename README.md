# ğŸ¤– Autonomous Robot Navigation â€“ Webots Simulation  
**(CNN + MLP + Rede Bayesiana + Reflexo HeurÃ­stico Integrado)**

SimulaÃ§Ã£o de navegaÃ§Ã£o autÃ´noma no **Webots** que combina percepÃ§Ã£o profunda (CNN + MLP), inferÃªncia probabilÃ­stica (Rede Bayesiana) e um **reflexo heurÃ­stico de emergÃªncia** para evitar colisÃµes. Projeto acadÃªmico/educacional para comparaÃ§Ã£o e validaÃ§Ã£o de estratÃ©gias hÃ­bridas de controle.

---

## ğŸ“ Estrutura do RepositÃ³rio

```
autonomous-robot-webots/
â”œâ”€â”€ worlds/
â”‚   â””â”€â”€ IA-20251.wbt
â”‚
â”œâ”€â”€ controllers/
â”‚   â”œâ”€â”€ intelligent_navigator_controller/
â”‚   â”‚   â”œâ”€â”€ intelligent_navigator_controller.py   # Controlador hÃ­brido (CNN+MLP+RB + reflexo)
â”‚   â”‚   â””â”€â”€ robot_perception_model.pth            # Pesos PyTorch do modelo de percepÃ§Ã£o
â”‚   â”‚
â”‚   â””â”€â”€ navigator_controller/
â”‚       â”œâ”€â”€ navigator_controller.py              
â”‚       â””â”€â”€ robot_perception_model.pth            
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”¬ Objetivo

Construir e testar um controlador hÃ­brido que:
- Use **visÃ£o (cÃ¢mera)** e **LIDAR** para percepÃ§Ã£o;
- Preveja **distÃ¢ncia** e **Ã¢ngulo** ao alvo via uma rede hÃ­brida (CNN + MLP);
- Converta essas estimativas em probabilidades e realize **inferÃªncia** numa **Rede Bayesiana** para escolher a aÃ§Ã£o;
- **Atue reflexivamente** (regra de emergÃªncia) quando um obstÃ¡culo estiver muito prÃ³ximo, priorizando seguranÃ§a.

---

## ğŸ§  DescriÃ§Ã£o tÃ©cnica do controlador (`intelligent_navigator_controller.py`)

### Principais blocos:
1. **PercepÃ§Ã£o hÃ­brida (HybridNavNet)**  
   - CNN branch para imagens (3 conv layers + pooling).  
   - LIDAR branch (MLP).  
   - Head regressora que prediz `[dist_pred, angle_pred]`.

2. **Mapeamento para probabilidades**  
   - `map_to_probabilities(dist_pred, angle_pred)` converte as saÃ­das contÃ­nuas em:
     - `prob_obstacle` (probabilidade de obstÃ¡culo perigoso)
     - `prob_target` (probabilidade de objetivo visÃ­vel / relevante)

3. **VerificaÃ§Ã£o visual direta do alvo**  
   - SegmentaÃ§Ã£o HSV para detectar cor amarela (alvo).  
   - Se alvo visÃ­vel e perto â†’ encerra com sucesso.

4. **Reflexo heurÃ­stico de emergÃªncia** (NOVO)  
   - Ativado quando `dist_pred < 0.30` m (threshold configurÃ¡vel).  
   - Calcula qual lado (esquerdo/direito) tem **mais espaÃ§o livre** usando leitura do LIDAR e janelas gaussianas de ponderaÃ§Ã£o.  
   - Executa uma manobra imediata (giro esquerdo/direito) e **continua** o loop (nÃ£o consulta a RB nesse passo).

5. **Rede Bayesiana (pgmpy)**  
   - VariÃ¡veis: `TargetVisible`, `ObstacleDetected`, `Direction`, `Action`.  
   - EvidÃªncia virtual (TabularCPD) atualizada a cada step.  
   - InferÃªncia via `VariableElimination` para escolher `Action` âˆˆ {SEGUIR, VIRAR_ESQ, VIRAR_DIR}.

6. **AtuaÃ§Ã£o**  
   - Mapeia `Action` para velocidades dos motores (`set_motor_speeds`), com `MAX_SPEED = 4.0`.

---

## âš™ï¸ Requisitos (ambiente)

- **Webots** (R2023b ou superior recomendado)  
- **Python 3.8+** executado pelo Webots controller (ou ambiente que Webots usa)
- Bibliotecas Python:

```bash
pip install torch numpy opencv-python pgmpy
```

> ğŸ’¡ *Em ambientes sem GPU, o PyTorch instala automaticamente a versÃ£o CPU.*

---

## â–¶ï¸ Como executar

1. Abra o **Webots**.  
2. Carregue o mundo:
   ```text
   File â†’ Open World â†’ worlds/IA-20251.wbt
   ```
3. No nÃ³ do robÃ´, selecione o controller:
   ```text
   intelligent_navigator_controller
   ```
   - Certifique-se de que o arquivo `intelligent_navigator_controller/robot_perception_model.pth` esteja presente.  
4. Pressione â–¶ï¸ **Play** para iniciar a simulaÃ§Ã£o.  
5. Observe o console do Webots â€” mensagens como:
   ```text
   Modelo carregado!
   Dist: 0.42m | Angle: 12.5Â° | P(T): 0.83 | P(O): 0.31 | Action: SEGUIR
   REFLEXO: dist=0.25 | Vira ESQUERDA (L=1.23 R=0.67)
   ```

---

## ğŸ”§ ParÃ¢metros importantes (onde ajustar)

- `MODEL_PATH` â€” caminho para pesos PyTorch (`robot_perception_model.pth`)  
- `IMG_HEIGHT`, `IMG_WIDTH` â€” dimensÃ£o de entrada da CNN (64 Ã— 64 por padrÃ£o)  
- `MAX_SPEED` â€” velocidade mÃ¡xima dos motores  
- **Threshold do reflexo:** `dist_pred < 0.30` (m) â€” ajusta a sensibilidade de seguranÃ§a  
- **Pesos gaussianos:** configuram a sensibilidade lateral no reflexo (`num_rays`, `Ïƒ`)  

---

## ğŸ§ª Comportamento esperado & testes

- **CenÃ¡rios tÃ­picos**:
  - Alvo visÃ­vel â†’ confianÃ§a alta em `TargetVisible` â†’ aÃ§Ã£o `SEGUIR`/`APPROACH`.  
  - ObstÃ¡culo prÃ³ximo â†’ reflexo de emergÃªncia gira para o lado com mais espaÃ§o.  
  - SituaÃ§Ãµes incertas â†’ RB combina evidÃªncias e escolhe aÃ§Ã£o probabilisticamente.  

- **MÃ©tricas Ãºteis para avaliaÃ§Ã£o**:
  - Tempo atÃ© alcanÃ§ar o alvo (quando consegue).  
  - NÃºmero de intervenÃ§Ãµes reflexas (quantas vezes reflexo foi acionado).  
  - ColisÃµes ou contatos com obstÃ¡culos.  
  - DistÃ¢ncia mÃ­nima ao obstÃ¡culo durante a navegaÃ§Ã£o.  

---

## â˜‘ï¸ Boas prÃ¡ticas e limitaÃ§Ãµes

- Arquive **pesos grandes** (datasets ou checkpoints extensos) fora do repositÃ³rio â€” use releases GitHub, Artifactory ou links para armazenamento (Google Drive, S3).  
- A inferÃªncia em tempo real pode exigir CPU moderado; se usar GPU, configure Webots para usar intÃ©rprete com CUDA se disponÃ­vel.  
- A lÃ³gica de reflexo Ã© propositalmente simples e segura â€” pode ser aprimorada por heurÃ­sticas mais finas ou por uma polÃ­tica de controle aprendido.  

---

## ğŸ‘¥ Autoria / Colaboradores

- **Dely Silva** â€” desenvolvimento do controlador hÃ­brido e integraÃ§Ã£o  

*(adicione outros colaboradores conforme necessÃ¡rio)*

---

## ğŸ“‚ Arquivos chave

- `controllers/intelligent_navigator_controller/intelligent_navigator_controller.py` â€” controlador completo (percepÃ§Ã£o, RB, reflexo).  
- `controllers/intelligent_navigator_controller/robot_perception_model.pth` â€” pesos do modelo PyTorch (nÃ£o incluÃ­dos automaticamente; coloque aqui).  
- `worlds/IA-20251.wbt` â€” mundo Webots de teste.  

---

## ğŸ”œ PrÃ³ximos passos sugeridos

- Coletar mÃ©tricas automÃ¡ticas e salvar resultados (`.csv`) por execuÃ§Ã£o.  
- Implementar fallback para recarregar o modelo se `robot_perception_model.pth` nÃ£o for encontrado.  
- Ajustar thresholds e ponderaÃ§Ãµes do reflexo via parÃ¢metros externos (`config.json`).  
- Documentar procedimento de treinamento do `robot_perception_model.pth` em `docs/` (se desejar incluir instruÃ§Ãµes de re-treino).  

---

> âœ… Este README descreve o controlador **hÃ­brido** (CNN + MLP + Rede Bayesiana) com o reflexo heurÃ­stico integrado â€” pronto para uso em simulaÃ§Ãµes Webots e comparaÃ§Ãµes experimentais.
